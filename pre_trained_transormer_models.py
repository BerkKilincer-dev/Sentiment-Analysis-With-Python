# -*- coding: utf-8 -*-
"""Pre-trained transormer models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zs0HgZpQ8wXcmuNFt8Ov3JTnNHaLODp4
"""

import transformers
from transformers import pipeline

pip install triton

"""Kurulumdan sonra, çalışma zamanını (runtime) yeniden başlatmanız gerekebilir (yukarıdaki menüden `Runtime > Restart runtime` seçeneğini kullanarak) veya bazen kütüphanenin doğru şekilde algılanması için tüm notebook'u yeniden çalıştırmanız gerekebilir. Yeniden başlattıktan sonra, `transformers` ve `pipeline` import eden hücreyi tekrar çalıştırın ve uyarının devam edip etmediğini kontrol edin."""

sentiment_pipeline = pipeline("sentiment-analysis")

sentence_1 = "i had a great time at the movie it was really funny"
sentence_2 = "i had a great time at the movie but the parking was terrible"
sentence_3 = "i had a great time at the movie but the parking wasn't great"
sentence_4 = "i went to see a movie"

print(sentence_1)
sentiment_pipeline(sentence_1)

test = sentiment_pipeline(sentence_1)
[sub['label'] for sub in test]

print(sentence_2)
sentiment_pipeline(sentence_2)

print(sentence_3)
sentiment_pipeline(sentence_3)

print(sentence_4)
sentiment_pipeline(sentence_4)

"""The default model isn't giving us great results for our neutral sentence. However there are loads of models we can choose to use that have been trained on different data with different parameters: https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads&search=sentiment

Let's try a specific model trained on tweets in the English language only and see if that improves our results.
"""

specific_model = pipeline("sentiment-analysis", model="finiteautomata/bertweet-base-sentiment-analysis")

print(sentence_1)
specific_model(sentence_1)

print(sentence_2)
specific_model(sentence_2)

print(sentence_3)
specific_model(sentence_3)

print(sentence_4)
specific_model(sentence_4)

"""1. "Binary" (İkili) vs "Multi-class" (Çoklu) Sınıflandırma
Default Model (DistilBERT): Sadece "Pozitif" veya "Negatif" seçeneklerine sahip. Bu yüzden nötr bir cümle gördüğünde (Sentence 4), onu ya çok iyi ya da çok kötü diye etiketlemek zorunda kalıyor. Sonuçta 0.98 gibi yüksek bir skorla yanılıyor.

Özel Model (BERTweet): İçinde "Nötr" (NEU) seçeneği de var. Bu sayede duygusuz metinleri başarıyla ayırt edebiliyor.

Ders: Eğer gerçek dünya verileriyle (nötr cümlelerin bol olduğu) çalışıyorsan, mutlaka nötr sınıfı olan bir model seçmelisin.

2. Domain (Alan) Uyumu
BERTweet, Twitter verileriyle eğitilmiştir. Bu yüzden kısa, gündelik ve "ama/fakat" içeren karmaşık sosyal medya dilini anlamada, standart bir kitap/makale setinde eğitilmiş modelden daha başarılıdır.

Ders: Modeli nerede kullanacaksan (finans haberleri mi, tweetler mi, akademik makaleler mi?), o alanda eğitilmiş bir "pre-trained" model seçmek başarını %20-%30 artırır.

3. "Confidence Score" (Güven Skoru) Aldatıcı Olabilir
İlk modelin nötr cümleye %98 pozitif demesi, modelin çok emin ama tamamen haksız olduğunu gösteriyor.

Ders: Yüksek olasılık skorları her zaman "doğru sonuç" demek değildir. Modelin eğitildiği sınıfların dışına çıkıldığında bu skorlar anlamsızlaşır.

4. Karmaşık Cümlelerde (Sentence 3) Kararsızlık
Sentence 3: "I had a great time at the movie but the parking wasn't great"

Burada ilginç bir durum var: İlk model buna %99 negatif derken, ikinci model (BERTweet) %62 pozitif diyor.

Neden? Çünkü cümlenin yarısı çok iyi, yarısı kötü. Bir model "but"tan sonrasına odaklanırken, diğeri cümledeki "great" kelimelerinin ağırlığına takılabiliyor.

Ders: Hiçbir model %100 kusursuz değildir. Çok kritik projelerde birden fazla modelin ortalamasını almak (Ensemble) daha güvenli sonuç verir.
"""