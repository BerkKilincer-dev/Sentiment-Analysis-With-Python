# -*- coding: utf-8 -*-
"""Practical Task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kTuG36ZV6BidBZ6WbhuMrroKw7873KGG
"""

import pandas as pd
import numpy as np
import re
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import transformers
from transformers import pipeline
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn import metrics
from itertools import chain
from nltk import NaiveBayesClassifier

!pip install vaderSentiment

data = pd.read_csv("book_reviews_sample.csv") # the data should be in the same folder as your notebook
data.head()

data.info()

data['reviewText'][0]

"""Clean Data"""

# lowercase
data['reviewText_clean'] = data['reviewText'].str.lower()

# remove punctuation
data['reviewText_clean'] = data.apply(lambda x: re.sub(r"([^\w\s])", "", x['reviewText_clean']), axis=1)

data.head()

"""Rule-based sentiment with VADER"""

vader_sentiment = SentimentIntensityAnalyzer()

data['vader_sentiment_score'] = data['reviewText_clean'].apply(lambda review: vader_sentiment.polarity_scores(review)['compound'])

# create labels
bins = [-1, -0.1, 0.1, 1]
names = ['negative', 'neutral', 'positive']

data['vader_sentiment_label'] = pd.cut(data['vader_sentiment_score'], bins, labels=names)

data['vader_sentiment_label'].value_counts().plot.bar()

"""Pre-trained Transformer Model"""

transformer_pipeline = pipeline("sentiment-analysis")

transformer_labels = []

for review in data['reviewText_clean'].values:
    sentiment_list = transformer_pipeline(review)
    sentiment_label = [sent['label'] for sent in sentiment_list]
    transformer_labels.append(sentiment_label)

data['transformer_sentiment_label'] = transformer_labels

data['transformer_sentiment_label'].value_counts().plot.bar()

